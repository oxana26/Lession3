{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Установка библиотек"
      ],
      "metadata": {
        "id": "u5XBZEcx4i9S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2VEi-9q4bfz"
      },
      "outputs": [],
      "source": [
        "pip install transformers faiss-cpu sentence-transformers numpy scikit-learn torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.1. Подготовка данных и векторизация"
      ],
      "metadata": {
        "id": "ziU5fbgK4n59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import faiss\n",
        "\n",
        "# Пример базы знаний (документы)\n",
        "documents = [\n",
        "    \"Как сбросить пароль в системе?\",\n",
        "    \"Где найти настройки VPN?\",\n",
        "    \"Как установить обновление?\",\n",
        "    \"Почему не работает интернет?\",\n",
        "    \"Как создать новую учетную запись?\"\n",
        "]\n",
        "\n",
        "# 1. Векторизация с помощью TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_vectors = tfidf_vectorizer.fit_transform(documents).toarray()\n",
        "\n",
        "# 2. Векторизация с помощью BERT\n",
        "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
        "bert_vectors = model.encode(documents)\n",
        "\n",
        "# 3. Создание FAISS-индекса для BERT-векторов\n",
        "dim = bert_vectors.shape[1]\n",
        "index = faiss.IndexFlatIP(dim)  # Используем косинусное сходство\n",
        "index.add(bert_vectors.astype('float32'))\n"
      ],
      "metadata": {
        "id": "nUqg3Jdq4q_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2. Поиск похожих документов"
      ],
      "metadata": {
        "id": "B2wgHzUi4vp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_similar_documents(query, top_k=3, method='bert'):\n",
        "    # Векторизация запроса\n",
        "    if method == 'tfidf':\n",
        "        query_vec = tfidf_vectorizer.transform([query]).toarray()\n",
        "        # Сравнение с документами (косинусное сходство)\n",
        "        similarities = np.dot(query_vec, tfidf_vectors.T)[0]\n",
        "        top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
        "    elif method == 'bert':\n",
        "        query_vec = model.encode([query])\n",
        "        query_vec = query_vec.astype('float32')\n",
        "        # Поиск в FAISS\n",
        "        distances, top_indices = index.search(query_vec, top_k)\n",
        "\n",
        "    # Возврат результатов\n",
        "    results = [(documents[i], float(distances[0][j] if method == 'bert' else similarities[i]))\n",
        "               for j, i in enumerate(top_indices)]\n",
        "    return results\n",
        "\n",
        "# Пример поиска\n",
        "query = \"Не могу войти в аккаунт\"\n",
        "results = search_similar_documents(query, top_k=2, method='bert')\n",
        "print(\"Ближайшие документы:\")\n",
        "for doc, score in results:\n",
        "    print(f\"[Score: {score:.2f}] {doc}\")\n"
      ],
      "metadata": {
        "id": "M-in90yU4xqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.3. Генерация ответа (RAG)"
      ],
      "metadata": {
        "id": "aUaOmDU640Xl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Инициализация генеративной модели (ruGPT-3)\n",
        "generator = pipeline(\n",
        "    'text-generation',\n",
        "    model='sberbank-ai/rugpt3large_based_on_gpt2'\n",
        ")\n",
        "\n",
        "def generate_answer(query, context):\n",
        "    prompt = f\"Вопрос: {query}\\nКонтекст: {context}\\nОтвет:\"\n",
        "    answer = generator(\n",
        "        prompt,\n",
        "        max_length=200,\n",
        "        num_return_sequences=1,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    return answer[0]['generated_text'].split(\"Ответ:\")[-1].strip()\n",
        "\n",
        "# Пример генерации\n",
        "context = \" \".join([doc for doc, _ in results])\n",
        "answer = generate_answer(query, context)\n",
        "print(\"\\nСгенерированный ответ:\")\n",
        "print(answer)\n"
      ],
      "metadata": {
        "id": "dd-RDTIb42QV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Интеграция всех компонентов (RAG Pipeline)"
      ],
      "metadata": {
        "id": "BMMp0mdC47yR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RAGSystem:\n",
        "    def __init__(self):\n",
        "        # Инициализация моделей\n",
        "        self.tfidf_vectorizer = TfidfVectorizer()\n",
        "        self.embedding_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
        "        self.generator = pipeline('text-generation', model='sberbank-ai/rugpt3large_based_on_gpt2')\n",
        "        self.index = None\n",
        "        self.documents = []\n",
        "\n",
        "    def add_documents(self, docs):\n",
        "        self.documents = docs\n",
        "        # Обучение TF-IDF\n",
        "        self.tfidf_vectors = self.tfidf_vectorizer.fit_transform(docs).toarray()\n",
        "        # Векторизация BERT\n",
        "        bert_vectors = self.embedding_model.encode(docs)\n",
        "        # Создание FAISS-индекса\n",
        "        dim = bert_vectors.shape[1]\n",
        "        self.index = faiss.IndexFlatIP(dim)\n",
        "        self.index.add(bert_vectors.astype('float32'))\n",
        "\n",
        "    def search(self, query, top_k=3):\n",
        "        query_vec = self.embedding_model.encode([query]).astype('float32')\n",
        "        distances, indices = self.index.search(query_vec, top_k)\n",
        "        return [(self.documents[i], float(distances[0][j])) for j, i in enumerate(indices[0])]\n",
        "\n",
        "    def generate(self, query, context):\n",
        "        prompt = f\"Вопрос: {query}\\nКонтекст: {context}\\nОтвет:\"\n",
        "        answer = self.generator(prompt, max_length=200, temperature=0.7)[0]['generated_text']\n",
        "        return answer.split(\"Ответ:\")[-1].strip()\n",
        "\n",
        "# Использование\n",
        "rag = RAGSystem()\n",
        "rag.add_documents(documents)\n",
        "query = \"Как восстановить доступ к системе?\"\n",
        "results = rag.search(query)\n",
        "context = \" \".join([doc for doc, _ in results])\n",
        "answer = rag.generate(query, context)\n",
        "print(answer)\n"
      ],
      "metadata": {
        "id": "VDVydGzZ48TG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Оптимизации и улучшения\n",
        "1.\tДля больших данных используйте FAISS-IVF или HNSW:\n"
      ],
      "metadata": {
        "id": "-XqWvFUS5Ahs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quantizer = faiss.IndexFlatIP(dim)\n",
        "index = faiss.IndexIVFFlat(quantizer, dim, 100)  # 100 кластеров\n",
        "index.train(bert_vectors.astype('float32'))\n",
        "index.add(bert_vectors.astype('float32'))\n"
      ],
      "metadata": {
        "id": "nshvspLS5Cqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "2.\trag_model = pipeline('text2text-generation', model='facebook/rag-token-base')"
      ],
      "metadata": {
        "id": "n8yh0Ara5ufx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}